---
layout:
title: "유니티 ML-Agent 길찾기"
---

![Map](https://github.com/jaehyun0306/Machine-Learning/blob/main/%EC%A0%84%EC%B2%B4%EB%AA%A8%EC%8A%B5.PNG)

좌측 하단에 있는 AI가 녹색으로 되어있는 체크포인트를 거쳐서 목적지로 향하는 MLAgent

```
using Unity.MLAgents;
using Unity.MLAgents.Actuators;
using Unity.MLAgents.Sensors;

public class gRollerAgent : Agent
```
반드시 Unity.MLAgent가 포함되어야 하고 클래스는 Agent로 상속이 되게 해야한다.

```
public class gRollerAgent : Agent
{
    Rigidbody rBody;
    // Start is called before the first frame update
    void Start()
    {
        rBody = GetComponent<Rigidbody>();
    }

    public Transform Target;
    public GameObject Check1;
    public GameObject Check2;
    public GameObject Check3;
    public GameObject Check4;
    public GameObject Check5;
    public GameObject Check6;
    public GameObject Check7;
    public GameObject Check8;

    public GameObject viewModel = null;
```   
GameObject Check 1~8로 녹색 체크포인트 8개에 대한 정보를 가져온다.   

![Check](https://github.com/jaehyun0306/Machine-Learning/blob/main/Check.PNG)   
인스펙터 창에 Check1~8 부분에 하이레키창의 check 오브젝트들을 담는다.

```
    public override void OnEpisodeBegin()
    {
        //새로운 에피소드 시작시, 다시 에이전트의 포지션의 초기화
        // if the Agent fell, zero its momentum

            this.rBody.angularVelocity = Vector3.zero;
            this.rBody.velocity = Vector3.zero;
            this.transform.localPosition = new Vector3(-24.5f, 0.5f, -24.5f);

        Target.localPosition = new Vector3(25.5f, 0.5f, 5.5f);
        Check1.SetActive(true);
        Check2.SetActive(true);
        Check3.SetActive(true);
        Check4.SetActive(true);
        Check5.SetActive(true);
        Check6.SetActive(true);
        Check7.SetActive(true);
        Check8.SetActive(true);

    }
```
OnEpisodeBegin()은 새로운 에피소드가 시작 될 때마다 초기화시키는데, 여기선 매 에피소드마다 같은 위치로 AI를 위치시키고, CheckPoint 또한 다시 활성화 시키도록 한다.    

```
    /// <summary>
    /// 강화학습을 위한, 강화학습을 통한 행동이 결정되는 곳
    /// </summary>
    public override void OnActionReceived(ActionBuffers actionBuffers)
    {
        MoveAgent(actionBuffers.DiscreteActions);
        AddReward(-1 / MaxStep);
    }
```    
강화학습을 통한 행동이 결정되는 부분인데 AI가 목적지까지 최단거리로 갈수 있게 AddReward(-1/MaxStep)으로 행동을 할 때마다 점수를 깍도록 하였다.   

```
    public void MoveAgent(ActionSegment<int> act)
    {
        var dirToGo = Vector3.zero;
        var rotateDir = Vector3.zero;

        var forwardAxis = act[0];
        var rotateAxis = act[1];

        switch (forwardAxis)
        {
            case 1:
                dirToGo = transform.forward * m_ForwardSpeed;
                break;
        }

        switch (rotateAxis)
        {
            case 1:
                rotateDir = transform.up * -1f;
                break;
            case 2:
                rotateDir = transform.up * 1f;
                break;
        }

        transform.Rotate(rotateDir, Time.deltaTime * 100f);
        rBody.AddForce(dirToGo * forceMultiplier, ForceMode.VelocityChange);
    }
```
AI가 움직이는 방식을 나타내는 부분으로 switch(forwardAxis)는 0이면 정지, 1이면 전진이고 swith(rotateAxis) 부분은 0이면 정지, 1은 좌회전, 2는 우회전으로 회전하게 한다.   

![Move](https://github.com/jaehyun0306/Machine-Learning/blob/main/%EC%9B%80%EC%A7%81%EC%9E%84.PNG)   
사진의 표시된 부분을 2와 3으로 입력해줘서 이산적 입력값으로 움직이게 한다. 

```
    public void OnCollisionEnter(Collision collision)
    {
        if (collision.gameObject.CompareTag("Target"))
        {
            SetReward(+1.0f);
            EndEpisode();
        }

        if (collision.gameObject.CompareTag("Wall"))
        {
            SetReward(-1.0f);
            EndEpisode();
        }

        if (collision.gameObject.CompareTag("Check"))
        {
            AddReward(0.1f);
            collision.gameObject.SetActive(false);
        }
    }
```
충돌에 대한 판정을 하는 부분으로 AI가 충돌을 했을 때 충돌한 오브젝트의 태그정보를 가져온다.   
그래서 그 태그가 "Target"이면 점수를 얻고 에피소드를 끝내고 "Wall"이면 점수를 잃고 에피소드를 끝낸다.
그리고 "Check"에 닿으면 Target보다는 적은 점수를 얻고 그 에피소드 동안의 체크포인트는 비활성화 시킨다.

