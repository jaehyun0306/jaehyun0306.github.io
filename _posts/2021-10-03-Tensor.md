---
title: "텐서플로우 소개"
excerpt: "텐서플로우의 내용을 정리하기"
toc: true
toc_sticky: true
---

# 텐서

```python
import tensorflow as tf
import numpy as np
```

텐서는 일관된 유형(dtype이라고 불리는)을 가진 다차원 배열입니다.  
NumPy에 익숙하다면, 텐서는 일종의 Numpy.arrays와 같습니다.  
모든 텐서는 Python 숫자 및 문자열과 같이 변경할 수 없습니다.  
텐서의 내용을 업데이트할 수 없으며 새로운 텐서를 만들 수만 있습니다.

## 기초
기본 텐서를 만들어 봅시다.

다음은 "스칼라" 또는 "Rank-0" 텐서입니다. 스칼라는 단일 값을 포함하며 "축"은 없습니다.


```python
rank_0_tensor = tf.constant(4)
print(rank_0_tensor)
```

    tf.Tensor(4, shape=(), dtype=int32)  
    



"벡터" 또는 "Rank-1" 텐서는 값의 목록과 같습니다. 벡터에는 하나의 축이 있습니다.


```python
rank_1_tensor = tf.constant([2.0, 3.0, 4.0])
print(rank_1_tensor)
```

    tf.Tensor([2. 3. 4.], shape=(3,), dtype=float32)
    

"행렬" 또는 "Rank-2" 텐서에는 두 개의 축이 있습니다.


```python
rank_2_tensor = tf.constant([[1, 2], [3, 4], [5, 6]], dtype = tf.float16)
print(rank_2_tensor)
```

    tf.Tensor(
    [[1. 2.]
     [3. 4.]
     [5. 6.]], shape=(3, 2), dtype=float16)
    

"스칼라", "벡터", "행렬" 텐서의 형태

![scalar.png](https://raw.githubusercontent.com/jaehyun0306/jaehyun0306/main/%EC%8A%A4%EC%B9%BC%EB%9D%BC.PNG)

텐서에는 더 많은 축이 있을 수 있습니다.  
여기에서는 세 개의 축이 있는 텐서가 사용됩니다.


```python
rank_3_tensor = tf.constant([[[0, 1, 2, 3, 4], [5,6, 7, 8, 9]], 
                             [[10, 11, 12, 13, 14], [15, 16, 17, 18, 19]],
                             [[20, 21, 22, 23, 24], [25, 26, 27, 28, 29]]])
print(rank_3_tensor)
```

    tf.Tensor(
    [[[ 0  1  2  3  4]
      [ 5  6  7  8  9]]
    
     [[10 11 12 13 14]
      [15 16 17 18 19]]
    
     [[20 21 22 23 24]
      [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)
    

축이 두 개 이상인 텐서를 시각화하는 방법에는 여러 가지가 있습니다.

![3축텐서.png](https://raw.githubusercontent.com/jaehyun0306/jaehyun0306/main/3%EC%B6%95%ED%85%90%EC%84%9C.PNG)

np.array 또는 tensor.numpy 메서드를 사용하여 텐서를 NumPy배열로 변환할 수 있습니다.


```python
np.array(rank_2_tensor)
```




    array([[1., 2.],
           [3., 4.],
           [5., 6.]], dtype=float16)




```python
rank_2_tensor.numpy()
```




    array([[1., 2.],
           [3., 4.],
           [5., 6.]], dtype=float16)



텐서에는 종종 float와 int가 포함되지만 다음과 같은 유형도 있습니다.
* 복소수
* 문자열

기본 tf.Tensor 클래스에서는 텐서가 "직사각형"이어야 합니다. 즉 각 축을 따라 모든 요소의 크기가 같습니다.  
그러나 다양한 형상을 처리할 수 있는 특수 유형의 텐서가 있습니다.
* 비정형
* 희소

덧셈, 요소별 곱셈 및 행렬 곱셈을 포함하여 텐서에 대한 기본 산술을 수행할 수 있습니다.


```python
a = tf.constant([[1, 2],
                 [3, 4]])
b = tf.constant([[1, 1],
                 [1, 1]])

print(tf.add(a,b), "\n")
print(tf.multiply(a, b), "\n")
print(tf.matmul(a, b), "\n")  # 행렬곱
```

    tf.Tensor(
    [[2 3]
     [4 5]], shape=(2, 2), dtype=int32) 
    
    tf.Tensor(
    [[1 2]
     [3 4]], shape=(2, 2), dtype=int32) 
    
    tf.Tensor(
    [[3 3]
     [7 7]], shape=(2, 2), dtype=int32) 
    
    


```python
print(a + b, "\n")  #더하기
print(a * b, "\n")  #곱하기
print(a @ b, "\n")  #행렬곱
```

    tf.Tensor(
    [[2 3]
     [4 5]], shape=(2, 2), dtype=int32) 
    
    tf.Tensor(
    [[1 2]
     [3 4]], shape=(2, 2), dtype=int32) 
    
    tf.Tensor(
    [[3 3]
     [7 7]], shape=(2, 2), dtype=int32) 
    
    

텐서는 모든 종류의 연산에 사용됩니다.


```python
c = tf.constant([[4.0, 5.0], [10.0, 1.0]])

#  가장 큰 값 찾기
print(tf.reduce_max(c))
# 값이 가장 큰 인덱스 찾기
print(tf.argmax(c))
# 소프트맥스 계산
print(tf.nn.softmax(c))
```

    tf.Tensor(10.0, shape=(), dtype=float32)
    tf.Tensor([1 0], shape=(2,), dtype=int64)
    tf.Tensor(
    [[2.6894143e-01 7.3105854e-01]
     [9.9987662e-01 1.2339458e-04]], shape=(2, 2), dtype=float32)
    

## Shape
텐서는 Shape이 있습니다.  사용되는 일부 용어는 다음과 같습니다.
* Shape : 텐서의 각 차원의 길이(요소의 수)
* Rank : 텐서 축의 수 입니다. 스칼라는 Rank가 0이고 벡터의 Rank는 1이며 행렬의 rank는 2입니다.
* 축 또는 차원 : 텐서의 특정 차원
* 크기 : 텐서 총 항목 수, 곱 Shape 벡터

2차원 텐서에 대한 참조가 있을 수 있지만, Rank-2 텐서는 일반적으로 2D 공간을 설명하지 않습니다.

텐서 및 tf.TensorShape 객체에는 다음에 엑세스하기 위한 편리한 속성이 있습니다.


```python
rank_4_tensor = tf.zeros([3, 2, 4, 5])
```

![랭크4.png](https://raw.githubusercontent.com/jaehyun0306/jaehyun0306/main/%EB%9E%AD%ED%81%AC4.PNG)


```python
print("Type of every element:", rank_4_tensor.dtype)
print("Number of dimensions:", rank_4_tensor.ndim)
print("Shape of tensor", rank_4_tensor.shape)
print("Elements along axis 0 of tensor:", rank_4_tensor.shape[0])
print("Elements along the last axis of tensor:", rank_4_tensor.shape[-1])
print("Total number of elements (3*2*4*5):", tf.size(rank_4_tensor).numpy())
```

    Type of every element: <dtype: 'float32'>
    Number of dimensions: 4
    Shape of tensor (3, 2, 4, 5)
    Elements along axis 0 of tensor: 3
    Elements along the last axis of tensor: 5
    Total number of elements (3*2*4*5): 120
    

축은 종종 인덱스로 참조하지만, 항상 각 축의 의미를 추적해야 합니다.  
축이 전역에서 로컬로 정렬되는 경우가 종종 있습니다.  
배치 축이 먼저 오고 그 다음에 공간 차원과 각 위치의 특성이 마지막에 옵니다.  
이러한 방식으로 특성 벡터는 연속적인 메모리 영역입니다.

![축순서.png](https://raw.githubusercontent.com/jaehyun0306/jaehyun0306/main/%EC%B6%95%EC%88%9C%EC%84%9C.PNG)



## 인덱싱

### 단일 축 인덱싱
TensorFlow는 파이썬의 목록 또는 문자열 인덱싱과 마찬가지로   
표준 파이썬 인덱싱 규칙과 numpy 인덱싱의 기본 규칙을 따릅니다.
* 인덱스는 0에서 시작합니다.
* 음수 인덱스는 끝에서부터 거꾸로 계산합니다.
* 콜론, :은 슬라이스 start:stop:step에 사용됩니다.


```python
rank_1_tensor = tf.constant([0, 1, 1, 2, 3, 5, 8, 13, 21, 34])
print(rank_1_tensor.numpy())
```

    [ 0  1  1  2  3  5  8 13 21 34]
    

스칼라를 사용하여 인덱싱하면 축이 제거됩니다.


```python
print("First", rank_1_tensor[0].numpy()) 
print("Second", rank_1_tensor[1].numpy())
print("Last", rank_1_tensor[-1].numpy())
```

    First 0
    Second 1
    Last 34
    

: 슬라이스를 사용하여 인덱싱하면 축이 유지됩니다. 


```python
print("Everything", rank_1_tensor[ : ].numpy())
print("Befor 4:", rank_1_tensor[ :4].numpy()) # 처음부터 4번째까지
print("From 4 to the end", rank_1_tensor[4: ].numpy()) # 5번째부터 끝까지
print("From 2, before 7:", rank_1_tensor[2:7].numpy()) # 3번째부터 7번째까지
print("Every other item", rank_1_tensor[::2].numpy()) #처음주터 두칸씩 건너뛰기
print("Reversed:", rank_1_tensor[::-1].numpy()) # 거꾸로 나열
```

    Everything [ 0  1  1  2  3  5  8 13 21 34]
    Befor 4: [0 1 1 2]
    From 4 to the end [ 3  5  8 13 21 34]
    From 2, before 7: [1 2 3 5 8]
    Every other item [ 0  1  3  8 21]
    Reversed: [34 21 13  8  5  3  2  1  1  0]
    

### 다축 인덱싱
더 높은 Rank의 텐서는 여러 인덱스를 전달하여 인덱싱됩니다.

단일 축의 경우에서와 정확히 규칙이 각 축에 독립적으로 적용됩니다.


```python
print(rank_2_tensor.numpy())
```

    [[1. 2.]
     [3. 4.]
     [5. 6.]]
    

각 인덱스에 정수를 전달하면 결과는 스칼라입니다.


```python
print(rank_2_tensor[1, 1].numpy())
```

    4.0
    

정수와 슬라이스를 조합하여 인덱싱할 수 있습니다.


```python
print("Second row:", rank_2_tensor[1, :].numpy()) # 두번째 행
print("Second column:", rank_2_tensor[:, 1].numpy()) # 두번째 열
print("Last row:", rank_2_tensor[-1, :].numpy()) # 마지막 행
print("First item in last column:", rank_2_tensor[0, -1].numpy()) # 두번째 행의 첫번째 항목
print("Skip the first row:")  # 첫번째 행은 빼고
print(rank_2_tensor[1 :, :].numpy(), "\n")
```

    Second row: [3. 4.]
    Second column: [2. 4. 6.]
    Last row: [5. 6.]
    First item in last column: 2.0
    Skip the first row:
    [[3. 4.]
     [5. 6.]] 
    
    

다음은 3축 텐서의 예입니다.


```python
print("Everything :")
print(rank_3_tensor[:, :, :], "\n")
# 5번째 특성
print(rank_3_tensor[:, :, 4])
```

    Everything :
    tf.Tensor(
    [[[ 0  1  2  3  4]
      [ 5  6  7  8  9]]
    
     [[10 11 12 13 14]
      [15 16 17 18 19]]
    
     [[20 21 22 23 24]
      [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32) 
    
    tf.Tensor(
    [[ 4  9]
     [14 19]
     [24 29]], shape=(3, 2), dtype=int32)
    

배치에서 각 예의 모든 위치에서 마지막 특성 선택하기

![다섯번째 특성.png](https://raw.githubusercontent.com/jaehyun0306/jaehyun0306/main/5%EB%B2%88%EC%A7%B8%20%ED%8A%B9%EC%84%B1.PNG)

## Shape 조작하기
텐서의 Shape을 바꾸는 것은 매우 유용합니다.


```python
#  Shape은 각 차원의 크기를 표시하는 'TensorShape' 개체를 반환합니다.
var_x = tf.Variable(tf.constant([[1], [2], [3]]))
print(var_x.shape)
```

    (3, 1)
    


```python
# 이 개체를 파이썬 목록으로 변환할 수도 있습니다.
print(var_x.shape.as_list())
```

    [3, 1]
    

텐서를 새로운 Shape으로 바꿀 수 있습니다. 기본 데이터를 복제할 필요가 없으므로 재구성이 빠르고 저렴합니다.


```python
# 목록을 전달한다는 점에 유의합니다.
reshaped = tf.reshape(var_x, [1,3])
```


```python
print(var_x.shape)
print(reshaped.shape)
print("var_x의 형태 :", var_x, "\n")
print("reshaped의 형태 :", reshaped)
```

    (3, 1)
    (1, 3)
    var_x의 형태 : <tf.Variable 'Variable:0' shape=(3, 1) dtype=int32, numpy=
    array([[1],
           [2],
           [3]], dtype=int32)> 
    
    reshaped의 형태 : tf.Tensor([[1 2 3]], shape=(1, 3), dtype=int32)
    

데이터의 레이아웃은 메모리에서 유지되고 요청된 형상이 같은 데이터를 가리키는 새 텐서가 작성됩니다. TensorFlow는 C스타일 " 행 중심" 메모리 순서를 사용합니다. 여기에서 가장 오른쪽에 있는 인덱스를 증가시키면 메모리의 단일 단계에 해당합니다.


```python
print(rank_3_tensor)
```

    tf.Tensor(
    [[[ 0  1  2  3  4]
      [ 5  6  7  8  9]]
    
     [[10 11 12 13 14]
      [15 16 17 18 19]]
    
     [[20 21 22 23 24]
      [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)
    

텐서를 평평하게 하면 어떤 순서로 메모리에 배치되어 있는지 확인할 수 있습니다.


```python
print(tf.reshape(rank_3_tensor, [-1]))
```

    tf.Tensor(
    [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
     24 25 26 27 28 29], shape=(30,), dtype=int32)
    

일반적으로 tf.reshape의 합리적인 용도는 인접한 축을 결합하거나 분할하는 것입니다.

이 3x2x5 텐서의 경우, 슬라이스가 혼합되지 않으므로 (3x2)x5 또는 3x(2x5)로 재수성하는 것이 합리적입니다.


```python
print(tf.reshape(rank_3_tensor, [3*2, 5]), "\n")
print(tf.reshape(rank_3_tensor, [3, -1]))
```

    tf.Tensor(
    [[ 0  1  2  3  4]
     [ 5  6  7  8  9]
     [10 11 12 13 14]
     [15 16 17 18 19]
     [20 21 22 23 24]
     [25 26 27 28 29]], shape=(6, 5), dtype=int32) 
    
    tf.Tensor(
    [[ 0  1  2  3  4  5  6  7  8  9]
     [10 11 12 13 14 15 16 17 18 19]
     [20 21 22 23 24 25 26 27 28 29]], shape=(3, 10), dtype=int32)
    

![재구성.png](https://raw.githubusercontent.com/jaehyun0306/jaehyun0306/main/%EC%9E%AC%EA%B5%AC%EC%84%B1.PNG)

Shape을 변경하면 같은 총 요소 수를 가진 새로운 Shape에 대해 "작동"하지만, 축의 순서를 고려하지 않으면 별로 쓸모가 없습니다.

tf.reshape에서 축 교환이 작동하지 않으면, tf.transpose를 수행해야 합니다.


```python
# 하지말아야 하는 경우
# 모양을 변경할 때 축을 다시 정렬할 수 없습니다.
print(tf.reshape(rank_3_tensor, [2, 3, 5]), "\n")

print(tf.reshape(rank_3_tensor, [5,6]), "\n")

try:
  tf.reshape(rank_3_tensor, [7, -1])
except Exception as e:
  print(f"{type(e).__name__}: {e}")
```

    tf.Tensor(
    [[[ 0  1  2  3  4]
      [ 5  6  7  8  9]
      [10 11 12 13 14]]
    
     [[15 16 17 18 19]
      [20 21 22 23 24]
      [25 26 27 28 29]]], shape=(2, 3, 5), dtype=int32) 
    
    tf.Tensor(
    [[ 0  1  2  3  4  5]
     [ 6  7  8  9 10 11]
     [12 13 14 15 16 17]
     [18 19 20 21 22 23]
     [24 25 26 27 28 29]], shape=(5, 6), dtype=int32) 
    
    InvalidArgumentError: Input to reshape is a tensor with 30 values, but the requested shape requires a multiple of 7 [Op:Reshape]
    

![잘못된 예.png](https://raw.githubusercontent.com/jaehyun0306/jaehyun0306/main/%EC%9E%98%EB%AA%BB%EB%90%9C%20%EC%98%88.PNG)

## DTypes에 대한 추가 정보
tf.Tensor의 데이터 유형을 검사하려면, Tensor.dtype 속성을 사용합니다.

Python 객체에서 tf.Tensor를 만들 때 선택적으로 데이터 유형을 지정할 수 있습니다.

그렇지 않으면, TensorFlow는 데이터를 나타낼 수 있는 데이터 유형을 선택합니다. TensorFlow는 Python 정수를 tf.int32로, Python 부동 소수점 숫자를 tf.float32로 변환합니다. 그렇지 않으면, TensorFlow는 NumPy가 배열로 변환할 때 사용하는 것과 같은 규칙을 사용합니다.

유형별로 캐스팅할 수 있습니다,


```python
the_f64_tensor = tf.constant([2.2, 3.3, 4.4], dtype=tf.float64)
the_f16_tensor = tf.cast(the_f64_tensor, dtype=tf.float16)
the_u8_tensor = tf.cast(the_f16_tensor, dtype=tf.uint8)
print(the_f64_tensor)
print(the_f16_tensor)
print(the_u8_tensor)
```

    tf.Tensor([2.2 3.3 4.4], shape=(3,), dtype=float64)
    tf.Tensor([2.2 3.3 4.4], shape=(3,), dtype=float16)
    tf.Tensor([2 3 4], shape=(3,), dtype=uint8)
    

## 브로드캐스팅
브로드캐스팅은 NumPy의 브로드캐스팅 특성에서 빌린 개념입니다. 특정 조건에서 작은 텐서는 결환된 연산을 실행할 때 더 큰 텐서에 맞게 자동으로 확장 됩니다.

가장 간단하고 일반적인 경우는 스칼라에 텐서를 곱하거나 추가하려고 할 때 입니다. 이 경우, 스칼라느 ㄴ다른 인수와 같은 형상으로 브로드캐스트됩니다.


```python
x = tf.constant([1, 2, 3])

y = tf.constant(2)
z = tf.constant([2, 2, 2])

#아래 세가지는 다 같은 계산이다.
print(tf.multiply(x, 2))
print(x * y)
print(x * z)
```

    tf.Tensor([2 4 6], shape=(3,), dtype=int32)
    tf.Tensor([2 4 6], shape=(3,), dtype=int32)
    tf.Tensor([2 4 6], shape=(3,), dtype=int32)
    

마찬가지로, 크기가 1인 축은 다른 인수와 일치하도록 확장할 수 있습니다. 두 인수 모두 같은 계산으로 확장할 수 있습니다.

이 경우, 3x1 행렬에 요소별로 1x4 행렬을 곱하여 3x4행렬을 만듭니다. 선행 1이 선택사항 입니다. y의 shape은 [4]입니다.


```python
x = tf.reshape(x, [3,1])
y = tf.range(1, 5)
print(x, "\n")
print(y, "\n")
print(tf.multiply(x, y))
```

    tf.Tensor(
    [[1]
     [2]
     [3]], shape=(3, 1), dtype=int32) 
    
    tf.Tensor([1 2 3 4], shape=(4,), dtype=int32) 
    
    tf.Tensor(
    [[ 1  2  3  4]
     [ 2  4  6  8]
     [ 3  6  9 12]], shape=(3, 4), dtype=int32)
    

![3x4.png](https://raw.githubusercontent.com/jaehyun0306/jaehyun0306/main/3x4.PNG)

브로드캐스팅을 안쓴 연산


```python
x_stretch = tf.constant([[1, 1, 1, 1],
                         [2, 2, 2, 2],
                         [3, 3, 3, 3]])

y_stretch = tf.constant([[1, 2, 3, 4],
                         [1, 2, 3, 4],
                         [1, 2, 3, 4]])

print(x_stretch * y_stretch)
```

    tf.Tensor(
    [[ 1  2  3  4]
     [ 2  4  6  8]
     [ 3  6  9 12]], shape=(3, 4), dtype=int32)
    

대부분의 경우 브로드캐스팅은 브로드캐스트 연산으로 메모리에서 확정된 텐서를 구체화하지 않으므로 시간과 공간적으로 효율적입니다.


```python
print(tf.broadcast_to(tf.constant([1, 2, 3]), [3, 3]))
```

    tf.Tensor(
    [[1 2 3]
     [1 2 3]
     [1 2 3]], shape=(3, 3), dtype=int32)
    

## 비정형 텐서
일부 축을 따라 요소의 수가 가변적인 텐서를 "비정형"이라고 한다. tf.ragged를 사용합니다. 

비정형 데이터를 위해서 tf.ragged.RageedTensor를 사용합니다.

예를 들어, 아래 그림은 정규 텐서로 나타낼 수 없습니다.

![비정형.png](https://raw.githubusercontent.com/jaehyun0306/jaehyun0306/main/%EB%B9%84%EC%A0%95%ED%98%95.PNG)




```python
ragged_list = [[0, 1, 2, 3],
               [4, 5],
               [6, 7, 8],
               [9]]
```


```python
try:
  tensor = tf.constant(ragged_list)
except Exception as e:
  print(f"{type(e).__name__} : {e}")
```

    ValueError : Can't convert non-rectangular Python sequence to Tensor.
    

대신에 tf.ragged.constant를 사용하는 tf.RaggedTensor를 만듭니다.


```python
ragged_tensor = tf.ragged.constant(ragged_list)
print(ragged_tensor)
```

    <tf.RaggedTensor [[0, 1, 2, 3], [4, 5], [6, 7, 8], [9]]>
    

tf.RaggedTensor의 모양은 알수 없는 길이의 일부 축이 포합됩니다.


```python
print(ragged_tensor.shape)
```

    (4, None)
    

## 문자열 텐서
tf.string은 dtype이며, 텐서에서 문자열(가변 길이의 바이트 배열)과 같은 데이터를 나타낼수 있습니다.

문자열은 원자성이므로 Python 문자열과 같은 방식으로 인덱싱할 수 없습니다. 문자열의 길이는 텐서의 축 중의 하나가 아닙니다.

다음은 스칼라 문자열 텐서입니다.


```python
scalar_string_tensor = tf.constant("Gray wolf")
print(scalar_string_tensor)
```

    tf.Tensor(b'Gray wolf', shape=(), dtype=string)
    

문자열의 벡터는 다음과 같습니다.

![문자열백터.png](https://raw.githubusercontent.com/jaehyun0306/jaehyun0306/main/%EB%AC%B8%EC%9E%90%EC%97%B4%20%EB%B0%B1%ED%84%B0.PNG)


```python
# 길이가 다른 문자열 텐서가 세 개 있으면 괜찮습니다.
tensor_of_strings = tf.constant(["Gray wolf",
                                 "Quick brown fox",
                                 "Lazy dog"])
# Shape은 (3)입니다. 문자열 길이가 포함되지 않습니다.
print(tensor_of_strings)
```

    tf.Tensor([b'Gray wolf' b'Quick brown fox' b'Lazy dog'], shape=(3,), dtype=string)
    

위의 출력에서 b접두사는 tf.string dtype이 유니코드 문자열이 아니라 바이트 문자열임을 나타냅니다.

유니코드 문자를 전달하면 UTF-8로 인코딩됩니다.



```python
tf.constant("🥳👍")
```




    <tf.Tensor: shape=(), dtype=string, numpy=b'\xf0\x9f\xa5\xb3\xf0\x9f\x91\x8d'>



문자열이 있는 일부 기본 함수는 tf.strings을 포함하여 tf.strings.split에서 찾을 수 있습니다.


```python
# split을 사용하여 string을 텐서 세트로 분할할 수 있습니다.
print(tf.strings.split(scalar_string_tensor, sep= " "))
```

    tf.Tensor([b'Gray' b'wolf'], shape=(2,), dtype=string)
    


```python
# 하지만 string으로 된 텐서를 나누면 비정형 텐서가 됩니다.
# 각 문자열이 서로 다른 수의 파트로 분할될 수 있기 때문입니다.
print(tf.strings.split(tensor_of_strings))
```

    <tf.RaggedTensor [[b'Gray', b'wolf'], [b'Quick', b'brown', b'fox'], [b'Lazy', b'dog']]>
    

![문자열 비정형.png](https://raw.githubusercontent.com/jaehyun0306/jaehyun0306/main/%EB%AC%B8%EC%9E%90%EC%97%B4%20%EB%B9%84%EC%A0%95%ED%98%95.PNG)

tf.string.to_number:


```python
text = tf.constant("1 10 100")
print(tf.strings.to_number(tf.strings.split(text, " ")))
```

    tf.Tensor([  1.  10. 100.], shape=(3,), dtype=float32)
    

tf.cast를 사용하여 문자열 텐서를 숫자로 변환할 수는 없지만, 바이트로 변환한 다음 숫자로 변환할 수 있습니다. 


```python
byte_strings = tf.strings.bytes_split(tf.constant("Duck")) # "Duck"을 바이트로 분할
byte_ints = tf.io.decode_raw(tf.constant("Duck"), tf.uint8) # 숫자로 변환
print("Byte strings:", byte_strings)
print("Bytes:", byte_ints)
```

    Byte strings: tf.Tensor([b'D' b'u' b'c' b'k'], shape=(4,), dtype=string)
    Bytes: tf.Tensor([ 68 117  99 107], shape=(4,), dtype=uint8)
    


```python
# 또는 유니코드로 분할하여 디코딩합니다.
unicode_bytes = tf.constant("한글 🦆")
unicode_char_bytes = tf.strings.unicode_split(unicode_bytes, "UTF-8")
unicode_values = tf.strings.unicode_decode(unicode_bytes, "UTF-8")

print("\nUnicode bytes:", unicode_bytes)
print("\nUnicode chars:", unicode_char_bytes)
print("\nUnicode values:", unicode_values)
```

    
    Unicode bytes: tf.Tensor(b'\xed\x95\x9c\xea\xb8\x80 \xf0\x9f\xa6\x86', shape=(), dtype=string)
    
    Unicode chars: tf.Tensor([b'\xed\x95\x9c' b'\xea\xb8\x80' b' ' b'\xf0\x9f\xa6\x86'], shape=(4,), dtype=string)
    
    Unicode values: tf.Tensor([ 54620  44544     32 129414], shape=(4,), dtype=int32)
    

tf.string dtype은 TensorFlow의 모든 원시 바이트 데이터에 사용됩니다. tf.io 모듈에는 이밎 디코딩 및 csv구문 분석을 포함하여 데이터를 바이트로 변환하거나 바이트에서 변환하는 함수가 포함되어 있습니다.

## 희소 텐서
때때로 데이터는 매우 넓은 임베딩 공간처럼 희소합니다. TensorFlow는 tf.sparse와 희소 데이터를 효율적으로 저장하기 위한 관련 작업들을 지원합니다.

임베딩 : 자연어 처리 분야에서 사람이 쓰는 자연어를 기계가 이해할 수 있는 숫자형태인 vector로 바꾼 결과 혹은 그 일련의 과정 전체

![희소.png](https://raw.githubusercontent.com/jaehyun0306/jaehyun0306/main/%ED%9D%AC%EC%86%8C.PNG)


```python
sparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]],
                                       values=[1, 2],
                                       dense_shape=[3, 4])
print(sparse_tensor, "\n")

print(tf.sparse.to_dense(sparse_tensor))
```

    SparseTensor(indices=tf.Tensor(
    [[0 0]
     [1 2]], shape=(2, 2), dtype=int64), values=tf.Tensor([1 2], shape=(2,), dtype=int32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64)) 
    
    tf.Tensor(
    [[1 0 0 0]
     [0 0 2 0]
     [0 0 0 0]], shape=(3, 4), dtype=int32)
    
