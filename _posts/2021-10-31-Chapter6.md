---
title: "머신러닝 작업흐름"
excerpt: "머신러닝 작업흐름의 내용 요약"
toc: true
toc_sticky: true
---

# 6장 머신러닝 작업흐름 일반

머신러닝의 보편적 작업흐름은 크게 세 부분으로 구성됩니다.

* 과제 정의 : 문제 영역과 고객이 질문한 내용을 뒷받침하는 비즈니스 논리를 이해합니다. 데이터 집합을 수집하고 데이터가 나타내는 바를 파악한 후 작업에서 성공을 측정하는 방법을 선택합니다.
* 모델 개발 : 머신러닝 모델에서 데이터를 처리할 수 있도록 준비하고, 모델 평가 프로토콜과 이길 수 있는 간단한 기준선을 선택한 다음, 오버핏할 수 있는 일반화 능력을 갖춘 첫 번째 모델을 교육한 다음, 최대한의 일반화 성능을 달성할 때까지 모델을 정규화하고 조정합니다.
* 모델 배치: 이해 관계자에게 작업물을 전달하고, 웹 서버, 모바일 앱, 웹 페이지 또는 임베디드 장치로 모델을 전달하며, 야생에서의 모델 성능을 모니터링하고, 차세대 모델 구축에 필요한 데이터를 수집하기 시작합니다.

## 6.1  과제 정의
자신이 하고 있는 일의 맥락을 깊이 이해해야 합니다. 
* 고객이 왜 이 문제를 해결하려고 하는지 
* 모델을 어떻게 사용하고 고객의 비즈니스 프로세스에 어떻게 맞출 것인지 
* 어떤 종류의 데이터를 사용할 수 있거나 수집할 수 있는지 
* 비즈니스 문제에 매핑할 수 있는 기계 학습 과제는 무엇인지

### 6.1.1 문제 틀 짜기
머신러닝 문제를 구체화하려면 이해관계자들과의 많은 상세한 논의가 필요합니다. 
* 입력 데이터 : 예측하려고 하는 것, 대부분의 경우 사용자가 직접 새 데이터셋을 수집하고 주석을 달아야 합니다.
* 어떤 종류의 머신러닝 작업을 수행해야 하는지 알아야 한다 : 이항 분류, 다중 클래스 분류, 스칼라 회귀, 벡터 회귀, 멀티클래스, 멀티라벨 분류, 이미지 분할, 랭크, 클러스터링 등이 있습니다.


머신러닝이 없던 때에는 어떤 시스템이 있었고 어떻게 작동하는지 이해해야합니다.

특별히 처리해야 할 제약이 있는지 확인해야하고, 작업에 맞을 전체 context를 이해해야합니다

조사를 마쳤으면, 입력과 목표가 무엇인지, 그리고 문제가 어떤 종류의 머신러닝 과제로 매핑되는지 알아야 합니다.

* 입력이 주어지면 목표값을 예측할 수 있다는 가설을 세웁니다.
* 사용할 수 있는 데이터(또는 곧 수집할 데이터)가 입력과 목표값 간의 관계를 학습하는 데 충분한 정보를 제공한다는 가설을 세웁니다

작업 모형을 갖추기 전까지는 가설일 뿐이며 검증되거나 무효화되기를 기다리고 있습니다. 머신러닝으로 모든 문제를 해결할 수 있는 것은 아닙니다. 예측 정보를 많이 포함하고 있지 않으면 실패할 가능성이 높습니다.

### 6.1.2 데이터 집합 수집
작업의 특성을 이해하고 입력과 대상이 무엇인지 안 후에는 데이터 수집이 필요합니다.

알고리즘보다 데이터가 더 중요하다는 지적은 구글 연구진이 2009년 발표한 '데이터의 불합리한 효과'(유진 위그너의 1960년 저서 '자연과학에서의 수학의 불합리한 효과'에 대한 리프)에서 가장 유명합니다. 

지도 학습을 수행하는 경우 입력(예: 이미지)을 수집한 후에는 입력(예: 이미지 태그)에 대한 주석(예: 모델이 예측할 목표)이 필요합니다.

__데이터 주석 인프라에 투자__

데이터 주석 공정에 따라 목표물의 품질이 결정되고, 이는 다시 모형의 품질을 결정합니다.

최상의 옵션을 선택하려면 작업 중인 제약 조건을 고려해야합니다.

데이터 라벨 작성자가 주제 전문가여야 합니다

한 예로 뼈 골절의 CT 스캔에 주석을 다는 것은 의학 학위를 필요로 합니다.
데이터에 주석을 달아야 하는 전문 지식이 있다면, 사람들을 교육시키거나, 관련 전문가와 접촉해야합니다

하지만 전문가들이 어떻게 주석을 달 수 있는지 이해하지 못하면 데이터 세트를 이해할 수 없고 수동 기능 엔지니어링을 수행할 수 없습니다.

데이터에 레이블을 붙이기로 결정한 경우 주석을 기록하는 데 사용할 소프트웨어가 필요하고 생산적인 데이터 주석 소프트웨어는 많은 시간을 절약할 수 있습니다.

__비대표 데이터 주의__

머신러닝 모델은 이전에 본 것과 유사한 입력만 감지할 수 있습니다. 따라서 training에 사용되는 데이터가 production 데이터를 대표해야 합니다.

training 데이터는 production 데이터를 대표하지 않습니다.

가능하면 모델이 사용될 환경에서 직접 데이터를 수집합니다. 

production 데이터에 대한 훈련이 가능하지 않다면 training 데이터와 production 데이터가 어떻게 다른지 완전히 이해하고 이러한 차이를 적극적으로 수정해야 합니다.

개념 드리프트 : 시간이 지남에 따라 production 데이터의 속성이 변경되어 모델 정확도가 점차 저하될 때 발생합니다. 빠르게 개념 드리프트를 처리하려면 지속적인 데이터 수집, 주석 및 모델 재교육이 필요하다.

머신러닝은 training 데이터에 존재하는 패턴을 암기하는 데만 사용될 수 있습니다. 미래를 예측하기 위해 과거 데이터에 대해 훈련된 머신러닝을 사용하는 것은 미래가 과거와 같이 행동할 것이라는 가정을 하는 것입니다.

참고: 샘플링 편향의 문제
비대표 데이터의 특히 흔한 경우는 샘플링 편향이다. 표본 추출 치우침은 데이터 수집 공정이 예측하려는 것과 교호작용할 때 발생하며, 이로 인해 측정값의 편향이 발생합니다.

### 6.1.3 데이터 이해
모델을 training하기 전에 데이터를 탐색 및 시각화하여 예측 가능한 요소에 대한 통찰력을 얻고(기능 엔지니어링에 정보를 제공) 잠재적인 문제를 선별해야 합니다.

__데이터 시각화의 예__
* 데이터에 이미지 또는 자연어 텍스트가 포함된 경우 몇 가지 샘플(및 해당 레이블)을 직접 살펴보아야 합니다.
* 데이터에 숫자 형상이 포함되어 있는 경우 형상 값의 히스토그램을 그래프로 표시하여 사용된 값의 범위와 다른 값의 빈도를 파악하는 것이 좋습니다.
* 데이터에 위치 정보가 포함되어 있으면 지도에 표시합니다.
* 일부 샘플에 일부 기능의 결측값이 있으면 데이터를 준비할 때 이 문제를 해결해야 합니다.
* 분류 문제인 경우 데이터에 있는 각 클래스의 인스턴스 수를 인쇄합니다.
* 목표 누출 여부: 데이터에 실운영 환경에서 사용할 수 없는 대상에 대한 정보를 제공하는 기능이 있는지 확인합니다. 데이터의 모든 기능이 운영 환경에서도 동일한 형태로 제공되는지 항상 생각해야 합니다.

### 6.1.4 성공의 척도를 선택
프로젝트에서 성공을 거두려면 먼저 성공이라는 의미를 정확하게 정의해야 합니다.

 정확성과 기억력, 고객 유지율 등 성공을 위한 지표는 프로젝트 전반에 모든 기술적 선택을 안내할 것입니다. 
 
 고객의 비즈니스 성공과 같은 상위 수준의 목표와 직접 연계되어야 합니다.

모든 클래스가 동일한 가능성이 있는 균형 분류 문제의 경우, 수신기 작동 특성 곡선(ROC AUC) 정확도와 영역이 일반적인 지표입니다.

클래스 불균형 문제, 순위 문제 또는 다중 레이블 분류의 경우 정밀도 및 호출뿐만 아니라 가중 형태의 정확도 또는 ROC AUC를 사용할 수 있습니다. 또한 성공을 측정하기 위해 자신만의 사용자 지정 메트릭을 정의해야 하는 경우도 흔합니다.

#### ROC AUC 곡선
다양한 임계값 설정에서 분류 문제에 대한 성능 측정입니다. ROC는 확률 곡선이고 AUC는 분리 가능성의 정도 또는 측도를 나타냅니다. 모형이 얼마나 계층을 구별할 수 있는지 알려줍니다. AUC가 높을수록 모형이 0 클래스를 0으로, 1 클래스를 1로 더 잘 예측합니다.

## 6.2 모델 개발
진행 상황을 어떻게 측정할 것인지 알고난 후의 단계입니다.

대부분의 튜토리얼 및 연구 프로젝트는 이 단계가 유일한 단계라고 가정합니다. 즉, 이미 수행된 것으로 간주되는 문제 정의 및 데이터 세트 수집을 건너뛰고, 다른 사용자가 처리하는 것으로 간주되는 모델 배포 및 유지 보수를 건너뜁니다.

### 6.2.1 자료 준비
딥러닝 모델은 일반적으로 원시 데이터를 수집하지 않습니다. 데이터 전처리는 원시 데이터를 신경망에 더 잘 적응하도록 만드는 것을 목표로 합니다. 

여기에는 벡터화, 정규화 또는 결측값 처리가 포함됩니다. 많은 사전 처리 기술은 도메인마다 다릅니다(예: 텍스트 데이터 또는 이미지 데이터)

__벡터화__

신경망의 모든 입력과 대상은 일반적으로 부동소수점 데이터의 텐서(또는 특정한 경우 정수나 문자열의 텐서)여야 합니다. 

소리, 이미지, 텍스트 등 처리해야 할 데이터가 무엇이든 간에 먼저 텐서로 전환해야 하며, 이 단계를 데이터 벡터화라고 합니다. 

__정규화__

일반적으로 상대적으로 큰 값(예: 네트워크의 초기 가중치보다 훨씬 큰 여러 자리 정수)을 사용하는 신경망 데이터나 이기종 데이터(예: 한 특징이 0-1이고 다른 특징이 100-200인 데이터)에 입력하는 것은 안전하지 않다. 이렇게 하면 대규모 그라데이션 업데이트가 트리거되어 네트워크가 수렴되지 않을 수 있습니다. 네트워크에서 보다 쉽게 학습하려면 데이터에 다음과 같은 특성이 있어야 합니다.

* 작은 값 사용 - 일반적으로 대부분의 값은 0-1 범위여야 합니다.
* 균일성: 즉, 모든 피쳐가 거의 동일한 범위의 값을 가져야 합니다.

또한 다음과 같은 엄격한 정규화 방법이 일반적이며 항상 필요한 것은 아니지만 도움이 될 수 있습니다.

* 평균이 0이 되도록 각 피쳐를 독립적으로 정규화합니다.
* 표준 편차가 1이 되도록 각 형상을 독립적으로 정규화합니다.

__결측값 처리__

때때로 데이터에 결측값이 있을 수 있습니다.

* 특성이 범주형인 경우 : "값이 누락됨"을 의미하는 새 범주를 작성하는 것이 안전합니다. 모델은 대상에 대해 이것이 내포하는 의미를 자동으로 학습합니다.

* 특성이 숫자인 경우 : 특성에 의해 형성된 잠재 공간에 불연속성이 생성되어 해당 형상에 대해 훈련된 모델이 일반화하기가 더 어려워질 수 있으므로 "0"과 같은 임의 값을 입력하면 안됩니다. 대신 결측값을 데이터 집합의 기능에 대한 평균값 또는 중위값으로 바꾸는 것을 고려해야 합니다. 다른 형상의 값이 주어진 형상의 값을 예측하도록 모델을 교육할 수도 있습니다.

테스트 데이터에 범주형 결측 기능이 있을 것으로 예상되지만 네트워크가 결측값 없이 데이터에 대해 학습된 경우, 네트워크는 결측값을 무시하는 방법을 배우지 않습니다. 이 경우 누락된 항목이 있는 교육 샘플을 인위적으로 생성해야 합니다. 일부 교육 샘플을 여러 번 복사하고 테스트 데이터에서 누락될 것으로 예상되는 범주형 기능 중 일부를 삭제해야 합니다.

### 6.2.2 평가규약 선택

모델의 목적은 일반화를 달성하는 것이며, 모델 개발 프로세스 전반에 걸쳐 내릴 모든 모델링 결정은 일반화 성과를 측정하기 위한 검증 지표에 의해 안내됩니다.

검증 프로토콜의 목표는 실제 프로덕션 데이터에서 선택한 성공 지표(예: 정확도)를 정확하게 추정하는 것입니다. 그 과정의 신뢰성은 유용한 모델을 구축하는 데 매우 중요합니다.


* 홀드아웃 유효성 검사 세트 유지 : 데이터가 많을 때 사용하는 방법
* K-폴드 교차 검증 수행 : 샘플 수가 너무 적어서 홀드아웃 검증을 신뢰할 수 없을 때 올바른 선택
* 반복 K-폴드 검증 수행 : 데이터가 거의 없을 때 매우 정확한 모델 평가 수행

### 6.2.3 기준선 돌파
모형 자체에 대한 작업을 시작하면 통계적 검정력을 달성하는 것이 초기 목표입니다. 즉, 간단한 기준선을 능가할 수 있는 작은 모형을 개발하는 것입니다.

이 단계에서 가장 중요한 세 가지 사항은 다음과 같습니다.

* 특성 엔지니어링 : 정보를 제공하지 않는 특성을 걸러내고 문제에 대한 지식을 활용하여 유용할 수 있는 새로운 특성을 개발합니다.
* 올바른 이전 아키텍처 선택 : 사용할 모델 아키텍처 유형은 무엇인지, 촘촘하게 연결된 네트워크, 컨브넷, 반복적인 신경 네트워크, 트랜스포머 등 딥러닝은 과제를 위한 좋은 접근법인지, 아니면 다른 것을 사용해야 하는지
* 충분한 훈련 구성 선택 : 어떤 손실 함수을 사용해야 하는지 배치 크기와 학습률은 어떻게 되는지

#### 올바른 손실 함수 선택
손실 함수는 데이터의 작은 배치(이상적으로 손실 함수는 단일 데이터 포인트만큼만 계산 가능해야 함)가 주어져야 하며, 역전파를 사용하여 네트워크를 훈련시킬 수 없어야 합니다. 

예를 들어, 널리 사용되는 분류 지표 ROC AUC는 직접 최적화될 수 없습니다. 따라서 분류 작업에서 교차 엔트로피와 같은 ROC AUC의 프록시 메트릭에 최적화하는 것이 일반적이다. 일반적으로 교차 엔트로피가 낮을수록 ROC AUC가 더 높아지기를 바랄 수 있습니다.

표는 몇 가지 일반적인 문제 유형에 대한 마지막 계층 활성화 및 손실 함수를 선택하는 데 도움이 될 수 있습니다.


표 넣기




대부분의 문제는 기존 템플릿이 있습니다. 선행 기술을 조사하여 작업에서 가장 잘 수행할 수 있는 기능 엔지니어링 기술과 모델 아키텍처를 식별해야합니다.

통계적 힘을 얻는 것이 항상 가능한 것은 아닙니다. 합리적인 아키텍처를 여러 번 시도해도 단순한 기준선을 넘을 수 없다면 입력 데이터에 질문에 대한 답이 없는 것일 수 있습니다.
* 입력이 주어지면 출력을 예측할 수 있다는 가설을 세웁니다.
* 사용 가능한 데이터가 입력과 출력 간의 관계를 학습하는 데 충분한 정보를 제공한다는 가설을 세웁니다.

위 두 가설이 틀리면 처음부터 다시 시작해야합니다.

### 6.2.4 스케일업 : 과대적합 모델 개발
예) 로지스틱 회귀 분석 모형은 MNIST에 대한 통계적 검정력이 있지만 문제를 잘 해결하기에는 충분하지 않습니다. 머신러닝의 보편적인 장력은 최적화와 일반화 사이입니다. 

이상적인 모델은 과소적합과 과적합, 과소용량과 과용량 사이의 경계에 서 있는 모델입니다. 이 경계가 어디에 있는지 알아내려면 먼저 경계를 넘어야 합니다.

얼마나 큰 모델이 필요한지 알아내려면, 과대적합 모델을 만들어야 합니다. 

1. 레이어를 추가합니다.
2. 층을 크게 만들어 주세요.
3. 에포크를 더 많이 훈련하세요.

훈련 손실 및 검증 손실은 물론 관심 있는 메트릭에 대한 교육 및 검증 값도 항상 모니터링합니다. 검증 데이터에 대한 모형의 성능이 저하되기 시작하면 과대적합이 이루어진 것입니다

### 6.2.5 모델 정규화 및 조정
통계적 힘을 얻고 과대적합을 할 수 있게 되면 일반화 성능을 최대화하는 것이 목표입니다.

이 단계에서는 모델이 최대한 좋은 결과를 얻을 때까지 반복적으로 모델을 수정하고 훈련하고 검증 데이터를 평가한 다음 다시 수정하고 반복합니다.

* 다른 아키텍처를 시도하거나 레이어를 추가 또는 제거합니다.
* dropout을 추가합니다.
* 모형이 작으면 L1 또는 L2 정규화를 추가합니다.
* 최적의 구성을 찾기 위해 다양한 하이퍼 파라미터(예: 계층당 단위 수 또는 최적화 프로그램의 학습 속도)를 사용합니다.
* 선택적으로 데이터 큐레이션 또는 특성 엔지니어링을 반복할 수 있습니다. 더 많은 데이터를 수집하고 주석을 달거나, 더 나은 특성을 개발하거나, 유용해 보이지 않는 특성을 제거할 수 있습니다.

Keras와 같은 자동화된 하이퍼 파라미터 튜닝 소프트웨어를 사용하여 이 작업의 상당 부분을 자동화할 수 있습니다.

검증 프로세스의 피드백을 사용하여 모델을 조정할 때마다 검증 프로세스에 대한 정보가 모델에 유출됩니다. 

여러 반복에 걸쳐 체계적으로 수행되면 검증 데이터에 대해 직접 훈련을 받은 모델이 없음에도 불구하고 모델이 검증 프로세스에 과대적합하게 됩니다. 이것은 평가 과정의 신뢰성을 떨어뜨립니다.

만족스러운 모델 구성을 개발했으면 사용 가능한 모든 데이터(훈련 및 검증)에 대해 최종 생산 모델을 교육하고 테스트 세트에서 마지막으로 평가할 수 있습니다. 테스트 세트의 성능이 검증 데이터에서 측정된 성능보다 훨씬 더 나쁜 것으로 판명되면 이는 검증 절차를 신뢰할 수 없거나 모형의 매개 변수를 조정하는 동안 검증 데이터에 과적합하기 시작했음을 의미할 수 있습니다. 이 경우 K-폴드 반복 유효성 검사와 같은 보다 안정적인 평가 프로토콜로 전환할 수 있습니다.

## 6.3 모델 배포


### 6.3.1 주주에게 모델을 설명하고 기대치를 설정

성공과 고객 신뢰는 지속적으로 고객의 기대에 부응하거나 그 이상을 달성하는 것입니다. 

실제로 제공하는 시스템은 그 그림의 절반에 불과합니다.

나머지 절반은 출시 전 적절한 기대치를 설정하고 있습니다.

AI 시스템에 대한 비전문가들의 기대는 종종 비현실적입니다. 

예를 들어, 그들은 시스템이 과제를 "이해"하고 과제 맥락에서 인간과 같은 상식을 행사할 수 있다고 기대합니다.

 이 문제를 해결하려면 모형의 실패 모드의 몇 가지 예제를 보여 주는 것을 고려해야 합니다(예: 잘못 분류된 표본 등).


또한 특히 이전에 사람이 처리했던 프로세스의 경우 인간 수준의 성능을 기대할 수 있습니다. 대부분의 머신러닝 모델은 인간이 만든 라벨에 근접하도록 (불완전하게) 훈련되었기 때문에 거의 도달하지 못합니다. 

모델 성능 기대치를 명확히 전달해야 합니다. "모델은 98%의 정확도를 가지고 있다"와 같은 추상적인 문장을 사용하는 것을 피하고, 예를 들어, 잘못된 부정 비율과 잘못된 긍정 비율에 대해 이야기하는 것이 좋습니다. "이러한 설정을 사용하면 부정 행위 탐지 모델은 5%의 거짓 음성 비율과 2.5%의 거짓 양성률을 갖습니다. 매일 평균 200건의 유효거래가 사기행위로 플래그가 지정돼 수작업 검토를 위해 발송되고, 평균 14건의 사기거래가 누락됐다. 평균 266건의 부정거래가 적발될 것이다." 모델의 성능 측정 기준을 비즈니스 목표와 명확하게 연관시킵니다.

또한 주요 시작 매개 변수(예: 트랜잭션에 플래그를 지정해야 하는 확률 임계값(임계값이 다르면 거짓 음수 및 거짓 긍정 비율이 다름)를 선택할 것인지 이해 관계자와 논의해야 합니다. 이러한 결정에는 비즈니스 맥락을 깊이 이해해야만 처리할 수 있는 트레이드오프가 포함됩니다.

### 6.3.2 추론 모델 발송
머신러닝 프로젝트는 훈련된 모델을 저장할 수 있는 코랩 노트북에 와도 끝나지 않습니다. 훈련 중에 조작한 것과 동일한 파이썬 모델 객체를 프로덕션으로 넣는 경우는 거의 없습니다.

Python이 아닌 다른 것으로 모델을 내보내는 것이 좋습니다.

* 운영 환경에서 Python을 전혀 지원하지 않을 수 있습니다
* 예를 들어, Python이 모바일 앱 또는 임베디드 시스템인 경우에 나머지 앱이 Python이 아닌 경우 모델을 서비스하기 위해 Python을 사용하면 상당한 오버헤드가 발생할 수 있습니다.

생산 모델은 훈련용이 아니라 예측(추론이라고 하는 단계) 출력에만 사용되므로 모델을 더 빠르게 만들고 메모리 공간을 줄일 수 있는 다양한 최적화를 수행할 수 있습니다.

__REST API로 모델 배포__

모델을 제품으로 바꾸는 일반적인 방법입니다.

서버나 클라우드 인스턴스에 TensorFlow를 설치하고 REST API를 통해 모델의 예측을 묻습니다.

플라스크(또는 다른 파이썬 웹 개발 라이브러리)와 같은 것을 사용하여 자신만의 Serving App을 구축하거나 TensorFlow의 자체 라이브러리를 사용하여 모델을 API로 제공할 수 있습니다. TensorFlow Serving을 사용하여 Keras 모델을 배포할 수 있습니다.

REST API로 모델을 배포하는 경우

* 모델의 예측을 소비할 애플리케이션은 인터넷에 신뢰할 수 있는 액세스를 갖게 될 것이다.
* 애플리케이션에는 엄격한 대기 시간 요구사항이 없습니다. 
* 추론을 위해 전송된 입력 데이터는 그다지 민감하지 않습니다. 

이미지 검색 엔진 프로젝트, 음악 추천 시스템, 신용카드 사기 탐지 프로젝트, 위성 이미지 프로젝트는 모두 REST API를 통해 서비스하기에 적합합니다.

REST API로 모델을 배포할 때 중요한 것은 코드를 직접 호스팅할지 아니면 완전히 관리되는 타사 클라우드 서비스를 사용할지 여부입니다.

__장치에 모델 배포__

스마트폰, 로봇의 내장형 ARM CPU 또는 작은 장치의 마이크로컨트롤러 등 해당 애플리케이션을 실행하는 동일한 장치에 모델을 사용해야하는 경우에 사용합니다.

장치에 모델을 사용하는 경우
* 모델에 엄격한 지연 시간 제약이 있거나 연결성이 낮은 환경에서 실행.
* 모델을 대상 장치의 메모리 및 전력 제약 조건에서 실행할 수 있을 정도로 충분히 작게 만들 수 있습니다.
* 런타임 효율성과 정확성 사이에는 항상 균형이 있기 때문에 메모리 및 전력 제약으로 인해 대형 GPU에서 실행할 수 있는 최상의 모델만큼 좋지 않은 모델을 제공해야 하는 경우가 많습니다.
* 입력 데이터는 엄격하게 중요하므로 원격 서버에서 해독할 수 없습니다.

사용 예
* 스팸 탐지 모델은 최종 사용자의 스마트폰에서 채팅 앱의 일부로 실행되어야 하는데, 이는 메시지가 종단 간 암호화되어 원격으로 호스팅된 모델에서 전혀 읽을 수 없기 때문이다. 
* 불량 쿠키 탐지 모델도 엄격한 대기 시간 제약이 있어 공장에서 실행해야 합니다. 다행히 이 경우 전력이나 공간 제약이 없어 GPU에서 실제로 모델을 실행할 수 있습니다.

스마트폰이나 임베디드 장치에 Keras 모델을 배포하려면 TensorFlow Lite를 사용해야 합니다. ARM64 기반 컴퓨터, 라즈베리 파이 또는 특정 마이크로컨트롤러뿐만 아니라 Android 및 iOS 스마트폰에서 실행되는 효율적인 장치 딥러닝 추론을 위한 프레임워크입니다. Keras 모델을 TensorFlow Lite 형식으로 바로 전환할 수 있는 변환기가 포함되어 있습니다.

__브라우저에서 모델 배포__

딥 러닝은 브라우저 기반 또는 데스크톱 기반 자바스크립트 응용 프로그램에서 자주 사용됩니다. 응용 프로그램이 REST API를 통해 원격 모델을 질의하는 것이 가능합니다.

브라우저에서 모델을 사용하는 경우

* 컴퓨팅을 최종 사용자에게 오프로드하여 서버 비용을 크게 절감할 수 있습니다.
* 입력 데이터는 최종 사용자의 컴퓨터 또는 전화기에 남아 있어야 합니다. 
* 애플리케이션에는 엄격한 지연 시간 제약이 있습니다. 최종 사용자의 노트북이나 스마트폰에서 실행되는 모델은 서버의 대형 GPU에서 실행되는 모델보다 속도가 느릴 수 있습니다.
* 모델이 다운로드되고 캐시된 후에도 연결 없이 계속 작동하려면 앱이 필요합니다.

모델이 사용자의 노트북이나 스마트폰의 CPU, GPU 또는 RAM을 독점하지 않을 정도로 작은 경우에만 이 옵션을 사용해야 합니다. 

전체 모델이 사용자의 장치에 다운로드되므로 모델에 대해 비밀로 유지할 필요가 없도록 해야 합니다.

단 중요한 데이터에 대해 훈련된 모델은 공개하지 않는 것이 좋습니다.

자바스크립트에서 모델을 배포하기 위해 텐서플로우 거의 모든 Keras API 뿐만 아니라 많은 하위 수준의 TensorFlow API를 구현합니다. 저장된 Keras 모델을 TensorFlow.js로 쉽게 가져와 브라우저 기반 JavaScript 앱 또는 데스크톱 전자 앱의 일부로 쿼리할 수 있습니다

__추론 모형 최적화__

사용 가능한 전력 및 메모리(스마트폰 및 임베디드 장치)에 엄격한 제약이 있는 환경이나 대기 시간이 짧은 애플리케이션에 배포할 때 추론을 위해 모델을 최적화하는 것이 중요합니다. TensorFlow.js로 가져오거나 TensorFlow Lite로 내보내기 전에 항상 모델을 최적화해야 합니다.

추론 모형 최적화를 사용하는 경우

* 가중치 가지치기 : 가장 중요한 항목만 유지하면 모델의 계층에서 매개변수 수를 크게 줄일 수 있고 적은 비용으로 모델의 메모리 및 컴퓨팅 설치 공간을 줄일 수 있습니다. 

 또한 적용할 가지치기 양을 조정하면 크기와 정확도 사이의 균형을 조정할 수 있습니다.
* 체중 정량화 : 가중치를 8비트 부호 정수(int8)로 정량화하면 float 32일 때보다 4배 작지만 원래 모델의 정확도에 가까운 추론 전용 모델을 얻을 수 있습니다.

### 6.3.3 실전에서 모델 모니터링
모델을 구축한 후에는 모델의 동작, 새 데이터에 대한 성능, 나머지 애플리케이션과의 상호 작용 및 궁극적으로 비즈니스 메트릭에 미치는 영향을 계속 모니터링해야 합니다.

모델 모니터링 예
* 새로운 음악 추천 시스템을 구축한 후 온라인 라디오에 대한 사용자 참여가 증가하는지
* 새로운 클릭률 예측 모델로 전환한 후 평균 광고 클릭률이 증가했는지

랜덤 A/B 테스트를 사용하여 모델 자체의 영향을 다른 변경으로부터 분리하는 것을 고려해야합니다.

사례의 일부는 새 모형을 통과해야 하고 다른 제어 부분 집합은 이전 공정을 고수해야 합니다.

생산 데이터에 대한 모델의 예측에 대해 정기적인 수동 감사를 실시합니다. 일반적으로 데이터 주석과 동일한 인프라를 재사용할 수 있습니다.

생산 데이터의 일부를 수동으로 주석을 달도록 전송하고 모델의 예측값을 새 주석과 비교합니다.

수동 감사가 불가능한 경우 사용자 설문 조사와 같은 대체 평가 방법을 고려해야합니다.

### 6.3.4 모델 유지
시간이 지남에 따라 생산 데이터의 특성이 바뀌어 모델의 성능과 관련성이 점차 저하됩니다.

모델이 출시되자마자 모델을 대체할 다음 세대를 훈련할 준비를 해야 합니다.
*  새로운 기능을 사용할 수 있는지, 레이블 세트를 확장해야 하는지 아니면 편집해야 하는지 생산 데이터의 변화를 생각해야 합니다.

* 데이터를 계속 수집하고 주석을 달 수 있으며 시간이 지남에 따라 주석 파이프라인을 계속 개선할 수 있습니다. 특히 현재 모형에 대해 분류하기 어려운 표본을 수집하는데 주의해야 합니다.

## 6.4 챕터 요약
* 기계 학습 프로젝트를 수행할 때 먼저 당면한 문제를 정의합니다.
  * 최종 목표는 무엇이고 제약은 무엇인지를 포함하여 현재 진행 중인 작업에 대한 더 넓은 맥락을 이해해야 합니다..
  * 데이터 세트를 수집하고 주석을 달 수 있습니다. 데이터를 자세히 이해해야 합니다.
  * 문제에 대한 성공을 측정하는 방법, 즉 검증 데이터에 대해 어떤 메트릭스를 모니터링할 것인지 선택합니다.

* 문제를 이해하고 적절한 데이터 세트를 확보했으면 모델을 개발합니다.
  * 데이터를 준비합니다.
  * hold-out이나 K-fold 평가 등 평가 프로토콜을 선택합니다. 
  * 통계 능력 달성을 달성합니다.
  * 스케일업: 오버핏할 수 있는 모델을 개발합니다.
  * 검증 데이터의 성능에 따라 모델을 정규화하고 하이퍼 파라미터를 조정할 수 있습니다. 

* 모델이 준비되고 테스트 데이터에 대해 우수한 성능을 제공하면 이제 다음과 같이 배포할 때입니다.

  * 먼저 이해관계자들과 적절한 기대치를 설정합니다.
  * 추론을 위해 최종 모델을 최적화하고 웹 서버, 모바일, 브라우저, 임베디드 디바이스 등 원하는 배치 환경에 모델을 제공할 수 있습니다.
  * 모델의 생산 성능을 모니터링하고 데이터를 계속 수집하여 차세대 모델을 개발할 수 있습니다.
